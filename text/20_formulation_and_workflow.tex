\chapter{Formulation and Workflow}

\label{ch:workflow}

%123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789
Here we present a formal description of our task and the basic overview of the proposed framework. In this context, we also briefly review the \gls{VL} system as our work is intended to work as its module.

\section{Videolytics}

\label{sec:vl}

Our work is designed to be a module of the analytical system for video processing and advanced analytics by \cite{videolytics}, called \gls{VL}. The goal of the system is to offer an effective way to produce an answer for various queries. Such requests may range from showing an advanced user interface for a live stream to retrieving statistical data from videos stored for offline processing. In order to compute all needed information, the system utilizes various \gls{ml} models. The system may be used to enhance the basic capabilities of security cameras and provide better data that can be utilized in various areas of city planning.

\Gls{VL} is designed as a modular system. This modularity is achieved by using a database as a core component of the system. Modules use the database as the only means of exchanging information. Such a solution makes it easier to add new modules, as their implementations are independent (aside from the \gls{api} defined by the database tables). An additional advantage of this approach is that it makes the data persistent and, therefore, it is possible to re-evaluate any experiments. For the more thorough description of \gls{VL}'s architecture please refer to \cite{videolyticsarch}. 

\section{Task Formulation}

Our goal is to implement the re-identification module for the \gls{VL}. As described in the Introduction, re-identification is, in essence, matching the same object across different frames (that is across different points in time or recordings from different cameras).

\subsection{Input}

\label{ssec:input}

%123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789
Firstly, let us describe the input of our module. To focus directly on the re-identification task, we use other \gls{VL}' modules to detect an object within the streams and crop out the relevant part of the frame. The input for our part of the system is then just the cropped images alongside additional metadata. We shall refer to this pre-processed input throughout the thesis as \glspl{det}. Let us formally define this notion of \glspl{det}.

Arguably the most important part of the \gls{det} is the image (crop) of the detected object. As \gls{VL} offers the system for selecting axis-aligned minimal bounding boxes of interesting objects, we focus on rectangular images only. We shall define universe of rectangular images $\mathcal{I}$, using standard RGB representation:

\begin{equation}
\mathcal{I} = \bigcup_{\substack{n \in \mathbb{N} \\ m \in \mathbb{N}}} \{0, 1, \ldots, 2^8-1\}^{3mn}
\label{eq:image}
\end{equation}


This representation describes an image as a matrix of pixels where each pixel is further split into triplets, each element describing one channel (red, green, and blue).

We formalize the notion of the source of the original stream (i.e., camera or the video file) where the detection comes from. For the given task, the only relevant information is the dimension of the stream. Aside from that, we assign each camera a unique identification number (to reflect the fact that we can indeed work with two different cameras of the same dimension). We can then formally define the universe of sources as:

$$\mathcal{C} = \{c_i, c_h, c_w \mid c_i \in \mathbb{N}, c_h \in \mathbb{N}, c_w \in \mathbb{N}\}
 = \mathbb{N}^3$$
 
We shall also refer to sources as cameras interchangeably due to consistency with the other work in the area and the underlying implementation.

%123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789
The final component of the \gls{det} is the additional metadata. For each detection, we record the relative position $x_0, y_0$, of the top left corner of the detection within the stream. Similarly, we denote $x_1, y_1$ relative position of the bottom right corner. Furthermore, we store a \emph{class} by each detection -- representing the detected object's class. Such class is an element of pre-defined vocabulary $V$. Our vocabulary is defined by pre-processing modules of the \gls{VL} systems. It is a relevant subset of classes used in the COCO dataset by \cite{cocodataset}:

$$V = \{\text{``person'', ``motorcycle'', ``car'', ``truck'', ``train'', ``bicycle'', ``bus''\}}$$


The last component of the metadata is a timestamp $t \in \mathbb{R}^+$. This notation allows us to define the universe of metadata~$\mathcal{M}$ as:

$$\mathcal{M} = \{{(x_0, x_1, y_0, y_1) \in [0,1]^4 \mid x_0 < x_1 \land y_0 < y_1}\} \times V \times \N \times \R$$

The first quadruplet represents the position, then a class mentioned, followed by the camera identifier, and the last number represents the timestamp.

Now, we can define the universe of \glspl{det} $\mathcal{D}$ as combination of images and metadata:

$$\mathcal{D} = \mathcal{I \times M}$$

\subsection{Task}

\label{ssec:task}

As usual in \gls{ml} tasks, we formulate our goal via a pair of input and the desired output (so-called ``golden truth''). Here we present an important distinction of our algorithm to the standard re-identification approach presented in the Introduction and \autoref{sec:person_reid}. The result of standard re-identification is a learned function that predicts if two input \glspl{det} are of the same object or not. On the other hand, our approach takes into consideration all presented \glspl{det} at the same time and partitions them based on the displayed object. It essentially works as a form of clustering.

Usually, the set presented on the input of our algorithm is a set of \glspl{det} extracted from simultaneous recordings from the cameras placed close together (i.e., we can expect objects to move from one camera to another or even to be recorded by multiple cameras at the same time). Working in the context of the whole set of \glspl{det} gives our algorithm an extra piece of information during the inference. For example if two \glspl{det} $d_0, d_1$ are visually different but both are similar to a third \gls{det} $d_2$, we may then conclude that $d_0$ and $d_1$ display the same object (as well as $d_2$) which we may not find out if we did not consider $d_2$.


As mentioned, to actually formalize our goal, we consider ``golden'' partitioning~$A$ of given \glspl{det}~$D$. This partitioning represents true re-identification of input \glspl{det}, i.e. an element~$a \in A$ contains all \glspl{det} that display one object. Our algorithm's goal is then to find this golden partitioning based on the input \glspl{det} $D$. Throughout the thesis we shall refer to any partitioning of set of \glspl{det} (both, the ``golden'' partitioning and the imperfect approximation our algorithm generates) as \glspl{iden}. A visualization of these concepts is available in \autoref{fig:structure_schema}.


\begin{figure}
    \centering
    \def\svgwidth{\textwidth}
    \input{img/structure_schema.pdf_tex}
    \caption{Visualization of different camera streams, detections, corresponding trajectories and identities}
    \label{fig:structure_schema}
\end{figure}



To summarize this concept, we shall refer to a pair of set of related \glspl{det} and the associated golden partitioning $A$ as a \gls{ses}. Formally we can define the universe $\mathcal{S}$ of all \glspl{ses} as:

\begin{equation*}
    \mathcal{S} = \left\{D \subset \mathcal{D},\,A \subset \mathcal{P(D)} \mid A\text{ is paritioning of }D \right\}
\end{equation*}

Our algorithm then works in context of one \gls{ses}~$S = (D, A), S \in \mathcal{S}$. A set of \glspl{det}~$D$ is given to the  algorithm and the goal is to recreate the hidden golden identities~$A$. Our algorithm assigns an arbitrary identification number to each identity, therefore we can formalize the desired output as following clustering function~$r_D^*$:

\begin{equation}
\begin{split}
&r_D^*: D \rightarrow \N \text{ s.t. }\\
&(\forall d \in D) (\forall d' \in D) ((r_D^*(d) = r_D^*(d')) \Leftrightarrow (\exists a \in A) (\{d, d'\} \subseteq a))
\label{eq:reidentification}
\end{split}
\end{equation}
Reconstruction of perfect function $r_D^*$ proves to be a hard problem, 
therefore we focus on construction of some approximation $r_D$.

As we previously noted this definition of re-identification task differs from the standard definition where we are given just two \glspl{det} and should output if given \glspl{det} are of the same object or not. However we can easily obtain the standard formulation once we obtain our output function $r_D$ as follows:

$$
r_D' : D^2 \to \{0, 1\} \text{ s.t. } (\forall d \in D) (\forall d' \in D) ((r_D'(d, d') = 1) \Leftrightarrow (r_D(d) = r_D(d')))
$$

Even though we described our algorithm in context of a single session, our goal is to make an algorithm that works well with any \gls{ses}. In order to provide unbiased estimation of the quality of our approach we provide evaluation that was chosen independently of the dataset we used for training \glspl{nn}.

% So far, we have presented our task's definition in the context of already given \gls{ses}. This definition as-is is enough for the work presented in this thesis as we work only with a few selected \glspl{ses}. Nevertheless, we proceed to shortly define the general case in this setting to provide building blocks for future work and motivation for some of our decisions. In a general case, we should not focus on one specific \gls{ses}, but we aim to design an algorithm that works across \glspl{ses}.


% However, there is no algorithm that would output suitable $r_D^*$ as in \autoref{eq:reidentification} for all the \glspl{ses}. To see that we just take any distinct pair of \glspl{det}~$D^\bot = \{d_1, d_2\}$. There exists two distinct partitioning and corresponding \glspl{ses}: $S_1 = (D^\bot, \{\{d_1, d_2\}\})$ and $S_2 = (D^\bot, \{\{d_1\}, \{d_2\}\})$. The output function $r_D$ of any algorithm can satisfy \autoref{eq:reidentification} either for $S_1$ or $S_2$ not for both.


% Therefore, we shall consider only ``possible'' \glspl{ses}. To properly define such \glspl{ses}, we shall assume some distribution $p_\mathcal{S}$ of \glspl{ses} (this distribution should reflect the distribution we aim the algorithm to work on, i.e. distribution of the \glspl{ses} in the real world). We can define possible \glspl{ses}~$\mathcal{S'}$ as:

% $$\mathcal{S}' = \{S \in \mathcal{S} \mid p_\mathcal{S}(S) > 0\}$$
% If every set of \glspl{det} is in at most one \glspl{ses}, i.e.:

% \begin{equation}
%     (\forall (D, A) \in \mathcal{S}')(\forall (D', A') \in \mathcal{S}') (D = D' \Rightarrow A = A'),
%     \label{eq:uniq_session}
% \end{equation}
% Then we can formulate our task by requiring the output function to hold
% condition in \autoref{eq:reidentification} for all
% \glspl{ses} from $\mathcal{S}'$.

% For an (arguably odd) case that \autoref{eq:uniq_session} does not hold, we
% define most likely partitioning for any set of \glspl{det}, given the distribution
% of \glspl{ses}~$p_\mathcal{S}$: 

% \begin{equation}
% A^*_D = \text{argmax}_A \pr_{(D', A')\sim p_\mathcal{S}} \left[A' = A \mid D' = D\right]
% \label{eq:mla}
% \end{equation}

% We can then obtain the valid task definition. We just replace the
% \glspl{iden}~$A$ in \autoref{eq:reidentification} by the most likely
% \glspl{iden}~$A_D^*$ and require the condition to hold over all sets of
% \glspl{det} from possible \glspl{ses}:

% \begin{equation}
% (\forall d \in D) (\forall d' \in D) ((r_D^*(d) = r_D^*(d')) \Leftrightarrow (\exists a \in A_D^*) (\{d, d'\} \subseteq a))
% \label{eq:formulation-final}
% \end{equation}


% Such definition is in agreement with the definition presented for the case where condition in \autoref{eq:uniq_session} holds.


% Finally, let us note that as we picked recordings (and corresponding \gls{ses}) for evaluation of our algorithm randomly, the results of such evaluation reflect the quality of the algorithm with respect to the task as defined by \autoref{eq:formulation-final}.


\section{Workflow}

\label{sec:workflow}

%123456789 123456789 123456789 123456789 123456789 123456789 123456789 123456789

In this section, we describe the general workflow of our re-identification algorithm. Note that, in this thesis, we present several different approaches for the task at hand. This section serves as an overview of the common workflow. Each step is then discussed more in-depth further in the thesis. For the diagram of the workflow, refer to \autoref{fig:workflow}.

\begin{figure}
    \centering
    \def\svgwidth{\textwidth}
    \input{img/workflow.pdf_tex}
    \caption[General workflow of our re-identification algorithm]{General workflow of our re-identification algorithm. Solid lines represent primary, intended dependencies.
    Dashed lines mark secondary, optional dependencies, that some algorithms may use.}
    \label{fig:workflow}
\end{figure}

Firstly, we shall extract the feature vectors from the images of the \glspl{det}. Such a feature vector should sufficiently describe the image as we shall not use the images directly further in the pipeline. There are several advantages of such representation. They primarily stem from the fact that once the feature vectors are extracted, the original images can be discarded. For one thing, we can lower the memory consumption for storing the data if the extracted feature vectors are smaller than the original cropped images. Another advantage is -- assuming that the feature extraction is an irreversible operation -- that it produces a layer of anonymization, which may be crucial for our task as we work with potentially sensitive data. We describe this step in \autoref{ch:features}.

After this feature vector extraction, we proceed to actual re-identification, which we discuss in \autoref{ch:iden_construction}. We usually split this process into two parts.

The first part is to group \glspl{det} that are close together (i.e., they originate from the same camera, have a very similar position within the frame, and have similar timestamp). We refer to this preliminary grouping as \emph{trajectories}. Although some very advanced strategies can be used even for this stage of the grouping, we shall only work with straight-forward approaches and focus more on the second step. We leave the experimenting with more thought-through approaches as feature work.

The second part is then to group generated \emph{trajectories} into \emph{identities}. In this step we need to merge trajectories of the same object across multiple cameras. That makes the spatial metadata less useful. Therefore, we focus more on the visual information in this part.

While this split is a bit arbitrary (and we indeed explore procedures that construct \glspl{iden} directly from \glspl{det} and feature vectors), it arises from practical use. We can use a straight-forward yet precise algorithm while we do not rely on the visual information for the first step. In the second step, we can leverage the fact that we have significantly fewer (by a few magnitudes) objects to merge.