%%% A template for a simple PDF/A file like a stand-alone abstract of the thesis.

\documentclass[12pt]{report}

\usepackage[a4paper, hmargin=1in, vmargin=1in]{geometry}
\usepackage[a-2u]{pdfx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{textcomp}

\begin{document}

%% Do not forget to edit abstract.xmpdata.

The wide usage of surveillance cameras provides data that can be used in various areas, such as security and urban planning. An important stepping stone for useful information extraction is matching the seen object across different points in time or different cameras. In this work, we focus specifically on this part of the video processing, usually referred to as re-identification.

We split our work into two stages. In the first part, we focus on the spatial and temporal information regarding the detected objects. In the second part, we combine this metadata with the visual information. For the extraction of useful descriptors from the images, we use methods based on the color distribution as well as state-of-the-art deep neural networks. We also annotate a dataset to verify our approaches and provide a comprehensive evaluation. Additionally, we provide a custom tool we used to annotate the dataset.

\end{document}
